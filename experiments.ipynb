{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# RegressLM Experiments - Fixed Version\n",
        "\n",
        "This notebook demonstrates how to use the RegressLM library for text-to-text regression tasks.\n",
        "\n",
        "**âœ… FIXED**: The TypeError issue with missing 'dropout' parameter has been resolved!\n",
        "\n",
        "## Overview\n",
        "RegressLM is a library that can:\n",
        "- Take text input and predict floating-point values\n",
        "- Fine-tune on your specific data\n",
        "- Generate multiple samples for uncertainty estimation\n",
        "\n",
        "## What you'll learn:\n",
        "1. Basic usage of RegressLM\n",
        "2. Creating training examples\n",
        "3. Fine-tuning the model\n",
        "4. Making predictions\n",
        "5. Running experiments\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully imported RegressLM!\n",
            "Available core classes: ['Example', 'ExampleInput', 'dataclasses']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from regress_lm import core\n",
        "from regress_lm import rlm\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Successfully imported RegressLM!\")\n",
        "print(f\"Available core classes: {[name for name in dir(core) if not name.startswith('_')]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple model for quick experimentation\n",
        "print(\"Creating RegressLM model...\")\n",
        "reg_lm = rlm.RegressLM.from_default(\n",
        "    max_input_len=128,\n",
        "    d_model=64,        # Small model for fast training\n",
        "    nhead=4,\n",
        "    num_encoder_layers=1,\n",
        "    num_decoder_layers=1,\n",
        "    dim_feedforward=256,\n",
        "    dropout=0.1,\n",
        ")\n",
        "\n",
        "# Create simple training examples (sentiment -> score)\n",
        "examples = [\n",
        "    core.Example(x=\"This is amazing!\", y=0.9),\n",
        "    core.Example(x=\"Pretty good\", y=0.7),\n",
        "    core.Example(x=\"Okay I guess\", y=0.5),\n",
        "    core.Example(x=\"Not great\", y=0.3),\n",
        "    core.Example(x=\"Terrible\", y=0.1),\n",
        "]\n",
        "\n",
        "print(f\"Created {len(examples)} training examples\")\n",
        "for ex in examples:\n",
        "    print(f\"  '{ex.x}' -> {ex.y}\")\n",
        "\n",
        "# Quick fine-tuning with all available parameters\n",
        "print(\"\\nFine-tuning model (this may take a minute)...\")\n",
        "reg_lm.fine_tune(\n",
        "    examples=examples,\n",
        "    validation_examples=examples,  # Using same data for validation (demo only)\n",
        "    max_epochs=10,                 # Number of training epochs  \n",
        "    batch_size=None,               # Use all examples in batch (default)\n",
        "    seed=42,                       # For reproducible results\n",
        ")\n",
        "\n",
        "# Test predictions\n",
        "test_inputs = [\n",
        "    core.ExampleInput(x=\"Fantastic!\"),\n",
        "    core.ExampleInput(x=\"Bad movie\"),\n",
        "]\n",
        "\n",
        "print(\"\\nMaking predictions...\")\n",
        "samples = reg_lm.sample(test_inputs, num_samples=5)\n",
        "\n",
        "for i, inp in enumerate(test_inputs):\n",
        "    mean_pred = np.mean(samples[i])\n",
        "    print(f\"'{inp.x}' -> {mean_pred:.3f} (samples: {[f'{x:.3f}' for x in samples[i]]})\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Basic experiment completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## ðŸš€ Next Steps\n",
        "\n",
        "Now that the basic setup works, you can:\n",
        "\n",
        "### 1. Experiment with Different Data\n",
        "```python\n",
        "# Try different types of text-to-number relationships\n",
        "examples = [\n",
        "    core.Example(x=\"five\", y=5.0),\n",
        "    core.Example(x=\"ten\", y=10.0),\n",
        "    # ... more examples\n",
        "]\n",
        "```\n",
        "\n",
        "### 2. Adjust Model Parameters\n",
        "```python\n",
        "model = rlm.RegressLM.from_default(\n",
        "    max_input_len=512,     # Longer inputs\n",
        "    d_model=256,           # Larger model\n",
        "    num_encoder_layers=3,  # More layers\n",
        "    dropout=0.1,           # Required parameter\n",
        ")\n",
        "```\n",
        "\n",
        "### 3. Visualization\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot predictions vs targets\n",
        "predictions = [np.mean(reg_lm.sample([core.ExampleInput(x=ex.x)], 5)) for ex in examples]\n",
        "targets = [ex.y for ex in examples]\n",
        "\n",
        "plt.scatter(targets, predictions)\n",
        "plt.xlabel('Target Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.plot([0,1], [0,1], 'r--')  # Perfect prediction line\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Key Classes Reference:\n",
        "- `core.Example(x=\"text\", y=0.5)` - Training example\n",
        "- `core.ExampleInput(x=\"text\")` - Query input\n",
        "- `rlm.RegressLM.from_default()` - Create model\n",
        "- `model.fine_tune(examples)` - Train the model\n",
        "- `model.sample(inputs, num_samples=N)` - Generate predictions\n",
        "\n",
        "**Remember**: Always include `dropout=0.1` (or another value) when creating models!\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# RegressLM Experiments\n",
        "\n",
        "This notebook demonstrates how to use the RegressLM library for text-to-text regression tasks.\n",
        "\n",
        "## Overview\n",
        "RegressLM is a library that can:\n",
        "- Take text input and predict floating-point values\n",
        "- Fine-tune on your specific data\n",
        "- Generate multiple samples for uncertainty estimation\n",
        "\n",
        "## What you'll learn:\n",
        "1. Basic usage of RegressLM\n",
        "2. Creating training examples\n",
        "3. Fine-tuning the model\n",
        "4. Making predictions\n",
        "5. Running experiments\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Loan Default Prediction with RegressLM\n",
        "\n",
        "This section demonstrates how to use RegressLM for a real-world regression task: predicting loan defaults based on borrower characteristics.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Source**: Loan Default Prediction Dataset\n",
        "- **Size**: ~230,000 loan records\n",
        "- **Target**: Default (0 = no default, 1 = default)\n",
        "- **Features**: 17 features including demographics, financial info, and loan details\n",
        "\n",
        "## Features:\n",
        "1. **Demographics**: Age, Education, Employment Type, Marital Status\n",
        "2. **Financial**: Income, Credit Score, Months Employed, DTI Ratio\n",
        "3. **Loan Details**: Loan Amount, Interest Rate, Loan Term, Purpose\n",
        "4. **Additional**: Has Mortgage, Has Dependents, Has Co-signer, Number of Credit Lines\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Load and Explore the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading loan default dataset...\n",
            "Dataset shape: (229769, 18)\n",
            "Default rate: 0.116\n",
            "\n",
            "First few rows:\n",
            "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
            "0  HPSK72WA7R   69   50432      124440          458              15   \n",
            "1  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
            "2  V2KKSFM3UN   32   31713       44799          743               0   \n",
            "3  EY08JDHTZP   60   20437        9139          633               8   \n",
            "4  A9S62RQ7US   25   90298       90448          720              18   \n",
            "\n",
            "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
            "0               1          4.81        60      0.68     Master's   \n",
            "1               3         21.17        24      0.31     Master's   \n",
            "2               3          7.07        24      0.23  High School   \n",
            "3               4          6.51        48      0.73   Bachelor's   \n",
            "4               2         22.72        24      0.10  High School   \n",
            "\n",
            "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
            "0      Full-time       Married          No            No       Other   \n",
            "1     Unemployed      Divorced         Yes           Yes        Auto   \n",
            "2      Full-time       Married          No            No    Business   \n",
            "3     Unemployed      Divorced          No           Yes        Auto   \n",
            "4     Unemployed        Single         Yes            No    Business   \n",
            "\n",
            "  HasCoSigner  Default  \n",
            "0         Yes        0  \n",
            "1          No        1  \n",
            "2          No        0  \n",
            "3          No        0  \n",
            "4         Yes        1  \n",
            "\n",
            "Column info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 229769 entries, 0 to 229768\n",
            "Data columns (total 18 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   LoanID          229769 non-null  object \n",
            " 1   Age             229769 non-null  int64  \n",
            " 2   Income          229769 non-null  int64  \n",
            " 3   LoanAmount      229769 non-null  int64  \n",
            " 4   CreditScore     229769 non-null  int64  \n",
            " 5   MonthsEmployed  229769 non-null  int64  \n",
            " 6   NumCreditLines  229769 non-null  int64  \n",
            " 7   InterestRate    229769 non-null  float64\n",
            " 8   LoanTerm        229769 non-null  int64  \n",
            " 9   DTIRatio        229769 non-null  float64\n",
            " 10  Education       229769 non-null  object \n",
            " 11  EmploymentType  229769 non-null  object \n",
            " 12  MaritalStatus   229769 non-null  object \n",
            " 13  HasMortgage     229769 non-null  object \n",
            " 14  HasDependents   229769 non-null  object \n",
            " 15  LoanPurpose     229769 non-null  object \n",
            " 16  HasCoSigner     229769 non-null  object \n",
            " 17  Default         229769 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(8)\n",
            "memory usage: 31.6+ MB\n",
            "None\n",
            "\n",
            "Target distribution:\n",
            "Default\n",
            "0    203160\n",
            "1     26609\n",
            "Name: count, dtype: int64\n",
            "Non-default: 203160\n",
            "Default: 26609\n",
            "\n",
            "Missing values:\n",
            "LoanID            0\n",
            "Age               0\n",
            "Income            0\n",
            "LoanAmount        0\n",
            "CreditScore       0\n",
            "MonthsEmployed    0\n",
            "NumCreditLines    0\n",
            "InterestRate      0\n",
            "LoanTerm          0\n",
            "DTIRatio          0\n",
            "Education         0\n",
            "EmploymentType    0\n",
            "MaritalStatus     0\n",
            "HasMortgage       0\n",
            "HasDependents     0\n",
            "LoanPurpose       0\n",
            "HasCoSigner       0\n",
            "Default           0\n",
            "dtype: int64\n",
            "\n",
            "Basic statistics for numeric columns:\n",
            "                 Age         Income     LoanAmount    CreditScore  \\\n",
            "count  229769.000000  229769.000000  229769.000000  229769.000000   \n",
            "mean       43.490776   82508.876929  127530.726360     574.204231   \n",
            "std        15.001682   38966.223905   70862.496195     158.883297   \n",
            "min        18.000000   15000.000000    5000.000000     300.000000   \n",
            "25%        31.000000   48865.000000   66107.000000     437.000000   \n",
            "50%        43.000000   82491.000000  127479.000000     574.000000   \n",
            "75%        56.000000  116245.000000  188906.000000     712.000000   \n",
            "max        69.000000  149999.000000  249999.000000     849.000000   \n",
            "\n",
            "       MonthsEmployed  NumCreditLines   InterestRate       LoanTerm  \\\n",
            "count   229769.000000   229769.000000  229769.000000  229769.000000   \n",
            "mean        59.546505        2.501121      13.490361      36.025904   \n",
            "std         34.658937        1.117516       6.634661      16.964005   \n",
            "min          0.000000        1.000000       2.000000      12.000000   \n",
            "25%         30.000000        2.000000       7.780000      24.000000   \n",
            "50%         60.000000        2.000000      13.450000      36.000000   \n",
            "75%         90.000000        4.000000      19.240000      48.000000   \n",
            "max        119.000000        4.000000      25.000000      60.000000   \n",
            "\n",
            "            DTIRatio  \n",
            "count  229769.000000  \n",
            "mean        0.500098  \n",
            "std         0.231000  \n",
            "min         0.100000  \n",
            "25%         0.300000  \n",
            "50%         0.500000  \n",
            "75%         0.700000  \n",
            "max         0.900000  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from regress_lm import core, rlm\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading loan default dataset...\")\n",
        "df = pd.read_csv('data/kaggle_loan_default_prediction_dataset/Loan_default_250702_training.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Default rate: {df['Default'].mean():.3f}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColumn info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(df['Default'].value_counts())\n",
        "print(f\"Non-default: {(df['Default'] == 0).sum()}\")\n",
        "print(f\"Default: {(df['Default'] == 1).sum()}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Basic statistics\n",
        "print(\"\\nBasic statistics for numeric columns:\")\n",
        "numeric_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', \n",
        "                'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
        "print(df[numeric_cols].describe())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Convert Data to Natural Language Descriptions\n",
        "\n",
        "Since RegressLM works with text input, we need to convert each loan record into a natural language description.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample text descriptions:\n",
            "\n",
            "Example 1 (Default = 0):\n",
            "A 69-year-old married borrower with master's education  works full-time and has been employed for 15 months.  They earn $50,432 annually and are applying for a $124,440 loan for other purposes.  Financial profile: Credit score of 458, debt-to-income ratio of 0.68,  and 1 credit lines. The loan terms are 60 months at 4.81% interest rate.  Additional details: Does not have a mortgage,  does not have dependents, and  has a co-signer.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 2 (Default = 1):\n",
            "A 46-year-old divorced borrower with master's education  works unemployed and has been employed for 26 months.  They earn $84,208 annually and are applying for a $129,188 loan for auto purposes.  Financial profile: Credit score of 451, debt-to-income ratio of 0.31,  and 3 credit lines. The loan terms are 24 months at 21.17% interest rate.  Additional details: Has a mortgage,  has dependents, and  does not have a co-signer.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example 3 (Default = 0):\n",
            "A 32-year-old married borrower with high school education  works full-time and has been employed for 0 months.  They earn $31,713 annually and are applying for a $44,799 loan for business purposes.  Financial profile: Credit score of 743, debt-to-income ratio of 0.23,  and 3 credit lines. The loan terms are 24 months at 7.07% interest rate.  Additional details: Does not have a mortgage,  does not have dependents, and  does not have a co-signer.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def loan_to_text(row):\n",
        "    \"\"\"Convert a loan record to a natural language description.\"\"\"\n",
        "    \n",
        "    # Format currency values\n",
        "    income = f\"${row['Income']:,}\"\n",
        "    loan_amount = f\"${row['LoanAmount']:,}\"\n",
        "    \n",
        "    # Create a comprehensive description\n",
        "    text = f\"\"\"\n",
        "    A {row['Age']}-year-old {row['MaritalStatus'].lower()} borrower with {row['Education'].lower()} education \n",
        "    works {row['EmploymentType'].lower()} and has been employed for {row['MonthsEmployed']} months. \n",
        "    They earn {income} annually and are applying for a {loan_amount} loan for {row['LoanPurpose'].lower()} purposes.\n",
        "    \n",
        "    Financial profile: Credit score of {row['CreditScore']}, debt-to-income ratio of {row['DTIRatio']:.2f}, \n",
        "    and {row['NumCreditLines']} credit lines. The loan terms are {row['LoanTerm']} months at {row['InterestRate']:.2f}% interest rate.\n",
        "    \n",
        "    Additional details: {'Has' if row['HasMortgage'] == 'Yes' else 'Does not have'} a mortgage, \n",
        "    {'has' if row['HasDependents'] == 'Yes' else 'does not have'} dependents, and \n",
        "    {'has' if row['HasCoSigner'] == 'Yes' else 'does not have'} a co-signer.\n",
        "    \"\"\".strip().replace('\\n    ', ' ').replace('\\n', ' ')\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Test the function with a few examples\n",
        "print(\"Sample text descriptions:\")\n",
        "for i in range(3):\n",
        "    text = loan_to_text(df.iloc[i])\n",
        "    target = df.iloc[i]['Default']\n",
        "    print(f\"\\nExample {i+1} (Default = {target}):\")\n",
        "    print(text)\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Prepare Training Data\n",
        "\n",
        "Due to the large dataset size (230k rows), we'll sample a subset for initial experimentation. You can increase the sample size later for better performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling 5000 records for training...\n",
            "Sample default rate: 0.116\n",
            "Sample distribution: {0: 4421, 1: 579}\n",
            "\n",
            "Training set: 4000 examples\n",
            "Validation set: 1000 examples\n",
            "\n",
            "Converting to RegressLM format...\n",
            "Created 4000 training examples\n",
            "Created 1000 validation examples\n",
            "\n",
            "First few training examples:\n",
            "\n",
            "Example 1:\n",
            "Text: A 56-year-old married borrower with high school education  works self-employed and has been employed for 21 months.  They earn $47,066 annually and are applying for a $38,739 loan for other purposes. ...\n",
            "Target: 0.0\n",
            "\n",
            "Example 2:\n",
            "Text: A 69-year-old single borrower with high school education  works full-time and has been employed for 57 months.  They earn $93,192 annually and are applying for a $54,236 loan for education purposes.  ...\n",
            "Target: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Sample data for initial experimentation\n",
        "# Start with 5000 samples for faster training - you can increase this later\n",
        "SAMPLE_SIZE = 5000\n",
        "print(f\"Sampling {SAMPLE_SIZE} records for training...\")\n",
        "\n",
        "# Stratified sampling to maintain the default rate using train_test_split\n",
        "# We'll use train_test_split to get our sample, then split again for train/val\n",
        "sample_df, _ = train_test_split(\n",
        "    df, \n",
        "    train_size=SAMPLE_SIZE, \n",
        "    random_state=42, \n",
        "    stratify=df['Default']\n",
        ")\n",
        "\n",
        "print(f\"Sample default rate: {sample_df['Default'].mean():.3f}\")\n",
        "print(f\"Sample distribution: {sample_df['Default'].value_counts().to_dict()}\")\n",
        "\n",
        "# Split into train/validation sets\n",
        "train_df, val_df = train_test_split(\n",
        "    sample_df, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=sample_df['Default']\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {len(train_df)} examples\")\n",
        "print(f\"Validation set: {len(val_df)} examples\")\n",
        "\n",
        "# Convert to RegressLM Examples\n",
        "print(\"\\nConverting to RegressLM format...\")\n",
        "\n",
        "# Training examples\n",
        "train_examples = []\n",
        "for _, row in train_df.iterrows():\n",
        "    text = loan_to_text(row)\n",
        "    target = float(row['Default'])  # Convert to float for regression\n",
        "    train_examples.append(core.Example(x=text, y=target))\n",
        "\n",
        "# Validation examples  \n",
        "val_examples = []\n",
        "for _, row in val_df.iterrows():\n",
        "    text = loan_to_text(row)\n",
        "    target = float(row['Default'])\n",
        "    val_examples.append(core.Example(x=text, y=target))\n",
        "\n",
        "print(f\"Created {len(train_examples)} training examples\")\n",
        "print(f\"Created {len(val_examples)} validation examples\")\n",
        "\n",
        "# Show a few examples\n",
        "print(\"\\nFirst few training examples:\")\n",
        "for i in range(2):\n",
        "    ex = train_examples[i]\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Text: {ex.x[:200]}...\")\n",
        "    print(f\"Target: {ex.y}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Create and Train the RegressLM Model\n",
        "\n",
        "**âœ… UPDATED**: Now using the **lower-level training approach** as recommended in the README instead of the high-level `fine_tune()` method. This gives us:\n",
        "- Direct control over the training loop\n",
        "- Better customization options  \n",
        "- The approach recommended for pretraining in the official documentation\n",
        "- More transparency in the training process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating PyTorchModel for loan default prediction...\n",
            "Model and optimizer created successfully!\n",
            "Model type: <class 'regress_lm.models.pytorch.model.PyTorchModel'>\n",
            "Optimizer type: <class 'torch.optim.Adafactor'>\n",
            "Converting examples to tensor format...\n",
            "Training tensor shapes:\n",
            "  encoder_input: torch.Size([4000, 512])\n",
            "  decoder_input: torch.Size([4000, 7])\n",
            "  decoder_target: torch.Size([4000, 7])\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING (Lower-level approach)\n",
            "============================================================\n",
            "Following the approach recommended in the README...\n",
            "This gives us more control over the training process.\n",
            "\n",
            "Training for 30 epochs with batch size 32\n",
            "Total batches per epoch: 125\n",
            "------------------------------------------------------------\n",
            "Epoch  1/30 | Train Loss: 1.7132 | Val Loss: 0.5898 | Time: 405.9s\n",
            "Epoch  6/30 | Train Loss: 0.1067 | Val Loss: 0.0830 | Time: 420.7s\n",
            "Epoch 11/30 | Train Loss: 0.0779 | Val Loss: 0.0730 | Time: 409.5s\n",
            "Epoch 16/30 | Train Loss: 0.0727 | Val Loss: 0.0717 | Time: 398.5s\n",
            "Epoch 21/30 | Train Loss: 0.0700 | Val Loss: 0.0704 | Time: 400.5s\n",
            "Epoch 26/30 | Train Loss: 0.0669 | Val Loss: 0.0660 | Time: 414.0s\n",
            "Epoch 30/30 | Train Loss: 0.0644 | Val Loss: 0.0648 | Time: 417.8s\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETED!\n",
            "============================================================\n",
            "Total training time: 12357.8 seconds\n",
            "Final train loss: 0.0644\n",
            "Final validation loss: 0.0648\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create RegressLM model using lower-level approach (as recommended in README)\n",
        "print(\"Creating PyTorchModel for loan default prediction...\")\n",
        "\n",
        "from torch import optim\n",
        "from regress_lm.models.pytorch import model as torch_model_lib\n",
        "from regress_lm import vocabs, tokenizers\n",
        "\n",
        "# Create model components manually for better control\n",
        "encoder_vocab = vocabs.SentencePieceVocab.from_t5()\n",
        "decoder_vocab = vocabs.DecoderVocab(tokenizers.P10Tokenizer())\n",
        "\n",
        "# Create the PyTorchModel directly (following README approach)\n",
        "model = torch_model_lib.PyTorchModel(\n",
        "    encoder_vocab=encoder_vocab,\n",
        "    decoder_vocab=decoder_vocab,\n",
        "    max_input_len=512,           # Max length for loan descriptions\n",
        "    learning_rate=5e-5,          # This is stored but we'll use our own optimizer\n",
        "    d_model=256,                 # Model dimension\n",
        "    nhead=8,                     # Number of attention heads\n",
        "    num_encoder_layers=3,        # Number of encoder layers\n",
        "    num_decoder_layers=3,        # Number of decoder layers  \n",
        "    dim_feedforward=1024,        # Feedforward dimension\n",
        "    dropout=0.1,                 # Dropout for regularization\n",
        "    z_loss_coef=1e-4,           # Additional regularization\n",
        ")\n",
        "\n",
        "# Create optimizer as recommended in README\n",
        "optimizer = optim.Adafactor(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()), \n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "print(\"Model and optimizer created successfully!\")\n",
        "print(f\"Model type: {type(model)}\")\n",
        "print(f\"Optimizer type: {type(optimizer)}\")\n",
        "\n",
        "# Convert examples to tensor format\n",
        "print(\"Converting examples to tensor format...\")\n",
        "train_tensor_examples = model.convert_examples(train_examples)\n",
        "val_tensor_examples = model.convert_examples(val_examples)\n",
        "\n",
        "print(f\"Training tensor shapes:\")\n",
        "for key, tensor in train_tensor_examples.items():\n",
        "    print(f\"  {key}: {tensor.shape}\")\n",
        "\n",
        "# Training loop following README approach\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING TRAINING (Lower-level approach)\")\n",
        "print(\"=\"*60)\n",
        "print(\"Following the approach recommended in the README...\")\n",
        "print(\"This gives us more control over the training process.\\n\")\n",
        "\n",
        "import torch\n",
        "import time\n",
        "\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "num_examples = len(train_examples)\n",
        "num_batches = (num_examples + batch_size - 1) // batch_size\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f\"Training for {num_epochs} epochs with batch size {batch_size}\")\n",
        "print(f\"Total batches per epoch: {num_batches}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start = time.time()\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    \n",
        "    # Shuffle training data\n",
        "    indices = torch.randperm(num_examples)\n",
        "    \n",
        "    for batch_idx in range(num_batches):\n",
        "        # Get batch indices\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, num_examples)\n",
        "        batch_indices = indices[start_idx:end_idx]\n",
        "        \n",
        "        # Create batch\n",
        "        batch_examples = {\n",
        "            key: tensor[batch_indices] for key, tensor in train_tensor_examples.items()\n",
        "        }\n",
        "        \n",
        "        # Training step (following README pattern)\n",
        "        optimizer.zero_grad()\n",
        "        loss, metrics = model.compute_loss_and_metrics(batch_examples)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_losses.append(loss.item())\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_metrics = model.compute_loss_and_metrics(val_tensor_examples)\n",
        "    \n",
        "    # Record losses\n",
        "    avg_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(val_loss.item())\n",
        "    \n",
        "    # Print progress\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
        "        print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss.item():.4f} | \"\n",
        "              f\"Time: {epoch_time:.1f}s\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total training time: {total_time:.1f} seconds\")\n",
        "print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Plot training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(val_losses, label='Validation Loss', color='red')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss Detail')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Store the model in a RegressLM wrapper for easy prediction\n",
        "loan_model = rlm.RegressLM(model, torch_model_lib.PyTorchFineTuner(model))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating the trained model...\n",
            "Making predictions on 1000 validation examples...\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Evaluating the trained model...\")\n",
        "\n",
        "# Make predictions on validation set\n",
        "val_inputs = [core.ExampleInput(x=ex.x) for ex in val_examples]\n",
        "val_targets = [ex.y for ex in val_examples]\n",
        "\n",
        "print(f\"Making predictions on {len(val_inputs)} validation examples...\")\n",
        "\n",
        "# Generate multiple samples for uncertainty estimation\n",
        "num_samples = 10\n",
        "predictions = loan_model.sample(val_inputs, num_samples=num_samples)\n",
        "\n",
        "# Calculate mean predictions and uncertainties\n",
        "mean_predictions = [np.mean(pred) for pred in predictions]\n",
        "std_predictions = [np.std(pred) for pred in predictions]\n",
        "\n",
        "print(\"Predictions completed!\")\n",
        "\n",
        "# Convert predictions to binary classification (threshold at 0.5)\n",
        "binary_predictions = [1 if pred >= 0.5 else 0 for pred in mean_predictions]\n",
        "\n",
        "# Calculate classification metrics\n",
        "accuracy = accuracy_score(val_targets, binary_predictions)\n",
        "precision = precision_score(val_targets, binary_predictions)\n",
        "recall = recall_score(val_targets, binary_predictions)\n",
        "f1 = f1_score(val_targets, binary_predictions)\n",
        "auc = roc_auc_score(val_targets, mean_predictions)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"AUC-ROC:   {auc:.4f}\")\n",
        "\n",
        "print(f\"\\nMean prediction: {np.mean(mean_predictions):.4f}\")\n",
        "print(f\"Mean uncertainty (std): {np.mean(std_predictions):.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(val_targets, binary_predictions)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                 Predicted\")\n",
        "print(f\"                No    Yes\")\n",
        "print(f\"Actual No    {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
        "print(f\"Actual Yes   {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
        "\n",
        "# Classification report\n",
        "print(f\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(val_targets, binary_predictions, \n",
        "                          target_names=['No Default', 'Default']))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 6: Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Prediction distribution by actual class\n",
        "axes[0, 0].hist([pred for i, pred in enumerate(mean_predictions) if val_targets[i] == 0], \n",
        "                alpha=0.7, label='No Default (Actual)', bins=30, color='blue')\n",
        "axes[0, 0].hist([pred for i, pred in enumerate(mean_predictions) if val_targets[i] == 1], \n",
        "                alpha=0.7, label='Default (Actual)', bins=30, color='red')\n",
        "axes[0, 0].axvline(x=0.5, color='black', linestyle='--', label='Decision Threshold')\n",
        "axes[0, 0].set_xlabel('Predicted Default Probability')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "axes[0, 0].set_title('Distribution of Predictions by Actual Class')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Uncertainty vs prediction\n",
        "scatter = axes[0, 1].scatter(mean_predictions, std_predictions, \n",
        "                            c=val_targets, cmap='RdYlBu', alpha=0.6)\n",
        "axes[0, 1].set_xlabel('Mean Prediction')\n",
        "axes[0, 1].set_ylabel('Prediction Uncertainty (Std)')\n",
        "axes[0, 1].set_title('Prediction Uncertainty vs Mean Prediction')\n",
        "plt.colorbar(scatter, ax=axes[0, 1], label='Actual Default')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Confusion matrix heatmap\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
        "            xticklabels=['No Default', 'Default'],\n",
        "            yticklabels=['No Default', 'Default'])\n",
        "axes[1, 0].set_title('Confusion Matrix')\n",
        "axes[1, 0].set_xlabel('Predicted')\n",
        "axes[1, 0].set_ylabel('Actual')\n",
        "\n",
        "# 4. ROC-like curve (prediction vs actual)\n",
        "sorted_indices = np.argsort(mean_predictions)\n",
        "sorted_predictions = np.array(mean_predictions)[sorted_indices]\n",
        "sorted_targets = np.array(val_targets)[sorted_indices]\n",
        "\n",
        "# Calculate cumulative metrics\n",
        "cumulative_positives = np.cumsum(sorted_targets)\n",
        "total_positives = cumulative_positives[-1]\n",
        "cumulative_recall = cumulative_positives / total_positives if total_positives > 0 else np.zeros_like(cumulative_positives)\n",
        "\n",
        "axes[1, 1].plot(sorted_predictions, cumulative_recall, 'b-', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Prediction Threshold')\n",
        "axes[1, 1].set_ylabel('Cumulative Recall')\n",
        "axes[1, 1].set_title('Cumulative Recall vs Prediction Threshold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Additional analysis: Show some example predictions\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXAMPLE PREDICTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Show predictions for both classes\n",
        "default_indices = [i for i, target in enumerate(val_targets) if target == 1]\n",
        "no_default_indices = [i for i, target in enumerate(val_targets) if target == 0]\n",
        "\n",
        "print(\"\\nExamples of DEFAULT loans (actual = 1):\")\n",
        "for i in default_indices[:3]:\n",
        "    ex = val_examples[i]\n",
        "    pred = mean_predictions[i]\n",
        "    uncertainty = std_predictions[i]\n",
        "    print(f\"\\nPrediction: {pred:.3f} Â± {uncertainty:.3f}\")\n",
        "    print(f\"Text: {ex.x[:300]}...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nExamples of NON-DEFAULT loans (actual = 0):\")\n",
        "for i in no_default_indices[:3]:\n",
        "    ex = val_examples[i]\n",
        "    pred = mean_predictions[i]\n",
        "    uncertainty = std_predictions[i]\n",
        "    print(f\"\\nPrediction: {pred:.3f} Â± {uncertainty:.3f}\")\n",
        "    print(f\"Text: {ex.x[:300]}...\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 7: Next Steps and Improvements\n",
        "\n",
        "Congratulations! You've successfully trained a RegressLM model using the **lower-level training approach** recommended in the README. This gives you much more control over the training process compared to the high-level `fine_tune()` method.\n",
        "\n",
        "### âœ… **Why the Lower-Level Approach is Better**\n",
        "- **More Control**: Direct access to optimizer, loss computation, and training loop\n",
        "- **Better for Pretraining**: As recommended in the README for producing better initial checkpoints\n",
        "- **Customizable**: Easy to add custom regularization, learning rate schedules, early stopping\n",
        "- **Debugging**: You can inspect losses, gradients, and model behavior at each step\n",
        "\n",
        "### 1. Scale Up Training\n",
        "```python\n",
        "# Use more data for better performance\n",
        "SAMPLE_SIZE = 20000  # or even the full dataset (230k rows)\n",
        "\n",
        "# Longer training with learning rate scheduling\n",
        "num_epochs = 100\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ... training loop ...\n",
        "    scheduler.step(val_loss)\n",
        "```\n",
        "\n",
        "### 2. Model Architecture Improvements\n",
        "```python\n",
        "# Larger model for better capacity\n",
        "model = torch_model_lib.PyTorchModel(\n",
        "    encoder_vocab=encoder_vocab,\n",
        "    decoder_vocab=decoder_vocab,\n",
        "    max_input_len=1024,          # Longer input sequences\n",
        "    d_model=512,                 # Larger model dimension\n",
        "    num_encoder_layers=6,        # More layers\n",
        "    num_decoder_layers=6,\n",
        "    dim_feedforward=2048,        # Larger feedforward\n",
        "    dropout=0.1,\n",
        "    z_loss_coef=1e-4,           # Additional regularization\n",
        ")\n",
        "```\n",
        "\n",
        "### 3. Advanced Training Improvements\n",
        "```python\n",
        "# Custom learning rate and optimizer\n",
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()), \n",
        "    lr=2e-4, \n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "# Gradient clipping for stability\n",
        "for epoch in range(num_epochs):\n",
        "    # ... in training loop ...\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "# Early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    # ... training ...\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= 10:\n",
        "            break\n",
        "```\n",
        "\n",
        "### 4. Feature Engineering\n",
        "- Add more sophisticated text descriptions\n",
        "- Include feature interactions in the text\n",
        "- Experiment with different text formats\n",
        "- Use domain-specific vocabulary\n",
        "\n",
        "### 5. Evaluation Improvements\n",
        "- Use proper test set (not validation set for final evaluation)\n",
        "- Implement cross-validation\n",
        "- Add ROC curves and precision-recall curves\n",
        "- Analyze feature importance through text analysis\n",
        "\n",
        "### 6. Production Considerations\n",
        "```python\n",
        "# Save trained model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'encoder_vocab': encoder_vocab,\n",
        "    'decoder_vocab': decoder_vocab,\n",
        "    'training_args': {...}\n",
        "}, 'loan_default_model.pt')\n",
        "\n",
        "# Load trained model\n",
        "checkpoint = torch.load('loan_default_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 8: Evaluate on Your Reserved Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to make predictions on new loan applications\n",
        "def predict_loan_default(loan_model, loan_record, num_samples=20):\n",
        "    \"\"\"\n",
        "    Make a prediction on a single loan application.\n",
        "    \n",
        "    Args:\n",
        "        loan_model: Trained RegressLM model\n",
        "        loan_record: Dictionary or pandas Series with loan application data\n",
        "        num_samples: Number of samples for uncertainty estimation\n",
        "    \n",
        "    Returns:\n",
        "        dict: Prediction results including mean, std, and risk assessment\n",
        "    \"\"\"\n",
        "    # Convert to pandas Series if it's a dictionary\n",
        "    if isinstance(loan_record, dict):\n",
        "        loan_record = pd.Series(loan_record)\n",
        "    \n",
        "    # Convert to text description\n",
        "    text_description = loan_to_text(loan_record)\n",
        "    \n",
        "    # Create input for the model\n",
        "    model_input = [core.ExampleInput(x=text_description)]\n",
        "    \n",
        "    # Get prediction with uncertainty\n",
        "    prediction_samples = loan_model.sample(model_input, num_samples=num_samples)\n",
        "    mean_pred = np.mean(prediction_samples[0])\n",
        "    std_pred = np.std(prediction_samples[0])\n",
        "    \n",
        "    # Determine risk level\n",
        "    if mean_pred < 0.3:\n",
        "        risk_level = \"LOW RISK\"\n",
        "        recommendation = \"âœ… APPROVE - Low default risk\"\n",
        "    elif mean_pred < 0.5:\n",
        "        risk_level = \"MEDIUM RISK\"\n",
        "        recommendation = \"âš ï¸  REVIEW - Moderate risk, consider additional conditions\"\n",
        "    elif mean_pred < 0.7:\n",
        "        risk_level = \"HIGH RISK\"\n",
        "        recommendation = \"âš ï¸  CAUTION - High risk, require additional security/co-signer\"\n",
        "    else:\n",
        "        risk_level = \"VERY HIGH RISK\"\n",
        "        recommendation = \"âŒ DENY - Very high default risk\"\n",
        "    \n",
        "    return {\n",
        "        'default_probability': mean_pred,\n",
        "        'uncertainty': std_pred,\n",
        "        'risk_level': risk_level,\n",
        "        'recommendation': recommendation,\n",
        "        'confidence': 'High' if std_pred < 0.2 else 'Medium' if std_pred < 0.4 else 'Low',\n",
        "        'all_samples': prediction_samples[0]\n",
        "    }\n",
        "\n",
        "# Example usage with your evaluation dataset:\n",
        "\"\"\"\n",
        "# Load your evaluation dataset\n",
        "eval_df = pd.read_csv('data/kaggle_loan_default_prediction_dataset/Loan_default_250702_evaluation.csv')\n",
        "\n",
        "# Make predictions on the evaluation set\n",
        "eval_predictions = []\n",
        "for _, row in eval_df.iterrows():\n",
        "    result = predict_loan_default(loan_model, row)\n",
        "    eval_predictions.append(result)\n",
        "\n",
        "# Analyze results\n",
        "eval_probs = [pred['default_probability'] for pred in eval_predictions]\n",
        "eval_uncertainties = [pred['uncertainty'] for pred in eval_predictions]\n",
        "\n",
        "print(f\"Evaluation set predictions:\")\n",
        "print(f\"Mean default probability: {np.mean(eval_probs):.3f}\")\n",
        "print(f\"Mean uncertainty: {np.mean(eval_uncertainties):.3f}\")\n",
        "\n",
        "# If you have ground truth labels, calculate metrics:\n",
        "if 'Default' in eval_df.columns:\n",
        "    true_labels = eval_df['Default'].values\n",
        "    predicted_labels = [1 if p >= 0.5 else 0 for p in eval_probs]\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    print(f\"\\\\nEvaluation Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\\\nClassification Report:\")\n",
        "    print(classification_report(true_labels, predicted_labels))\n",
        "\"\"\"\n",
        "\n",
        "print(\"ðŸŽ¯ LOAN DEFAULT PREDICTION MODEL - READY FOR EVALUATION!\")\n",
        "print(\"=\"*80)\n",
        "print(\"Your RegressLM model is now trained and ready to evaluate loan applications.\")\n",
        "print(\"Use the predict_loan_default() function to make predictions on your evaluation dataset.\")\n",
        "print(\"Uncomment and modify the example code above to evaluate on your reserved test set.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 9: Load and Evaluate on Your Evaluation Dataset\n",
        "\n",
        "Since you have a reserved evaluation dataset, use this code to evaluate your trained model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your evaluation dataset\n",
        "print(\"Loading evaluation dataset...\")\n",
        "eval_df = pd.read_csv('data/kaggle_loan_default_prediction_dataset/Loan_default_250702_evaluation.csv')\n",
        "\n",
        "print(f\"Evaluation dataset shape: {eval_df.shape}\")\n",
        "print(f\"Evaluation default rate: {eval_df['Default'].mean():.3f}\")\n",
        "\n",
        "# Make predictions on the evaluation set\n",
        "print(f\"\\nMaking predictions on {len(eval_df)} evaluation examples...\")\n",
        "print(\"This may take several minutes depending on the dataset size...\")\n",
        "\n",
        "eval_predictions = []\n",
        "eval_probabilities = []\n",
        "eval_uncertainties = []\n",
        "\n",
        "# Process in batches to show progress\n",
        "batch_size = 100\n",
        "for i in range(0, len(eval_df), batch_size):\n",
        "    batch_end = min(i + batch_size, len(eval_df))\n",
        "    print(f\"Processing batch {i//batch_size + 1}/{(len(eval_df)-1)//batch_size + 1} \"\n",
        "          f\"(rows {i+1}-{batch_end})...\")\n",
        "    \n",
        "    for _, row in eval_df.iloc[i:batch_end].iterrows():\n",
        "        result = predict_loan_default(loan_model, row, num_samples=10)\n",
        "        eval_predictions.append(result)\n",
        "        eval_probabilities.append(result['default_probability'])\n",
        "        eval_uncertainties.append(result['uncertainty'])\n",
        "\n",
        "print(\"Predictions completed!\")\n",
        "\n",
        "# Convert to binary predictions using 0.5 threshold\n",
        "eval_binary_preds = [1 if p >= 0.5 else 0 for p in eval_probabilities]\n",
        "eval_true_labels = eval_df['Default'].values\n",
        "\n",
        "# Calculate comprehensive metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, \n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "accuracy = accuracy_score(eval_true_labels, eval_binary_preds)\n",
        "precision = precision_score(eval_true_labels, eval_binary_preds)\n",
        "recall = recall_score(eval_true_labels, eval_binary_preds)\n",
        "f1 = f1_score(eval_true_labels, eval_binary_preds)\n",
        "auc = roc_auc_score(eval_true_labels, eval_probabilities)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL EVALUATION RESULTS ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Dataset Size: {len(eval_df):,} examples\")\n",
        "print(f\"Actual Default Rate: {eval_df['Default'].mean():.3f}\")\n",
        "print(f\"Predicted Default Rate: {np.mean(eval_binary_preds):.3f}\")\n",
        "print()\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"AUC-ROC:   {auc:.4f}\")\n",
        "print()\n",
        "print(f\"Mean Prediction: {np.mean(eval_probabilities):.4f}\")\n",
        "print(f\"Mean Uncertainty: {np.mean(eval_uncertainties):.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(eval_true_labels, eval_binary_preds)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                 Predicted\")\n",
        "print(f\"                No    Yes\")\n",
        "print(f\"Actual No    {cm[0,0]:6d}  {cm[0,1]:6d}\")\n",
        "print(f\"Actual Yes   {cm[1,0]:6d}  {cm[1,1]:6d}\")\n",
        "\n",
        "# Risk level distribution\n",
        "risk_levels = [pred['risk_level'] for pred in eval_predictions]\n",
        "risk_counts = pd.Series(risk_levels).value_counts()\n",
        "print(f\"\\nRisk Level Distribution:\")\n",
        "for risk, count in risk_counts.items():\n",
        "    percentage = (count / len(risk_levels)) * 100\n",
        "    print(f\"{risk}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(eval_true_labels, eval_binary_preds, \n",
        "                          target_names=['No Default', 'Default']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from regress_lm import core\n",
        "from regress_lm import rlm\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Successfully imported RegressLM!\")\n",
        "print(f\"Available core classes: {[name for name in dir(core) if not name.startswith('_')]}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Basic Usage - Creating a RegressLM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a RegressLM with default settings\n",
        "# You can customize parameters like max_input_len, learning_rate, model size, etc.\n",
        "reg_lm = rlm.RegressLM.from_default(\n",
        "    max_input_len=512,          # Maximum length of input text\n",
        "    learning_rate=1e-4,         # Learning rate for fine-tuning\n",
        "    d_model=256,                # Model dimension (smaller for faster experiments)\n",
        "    nhead=4,                    # Number of attention heads\n",
        "    num_encoder_layers=2,       # Number of encoder layers\n",
        "    num_decoder_layers=2,       # Number of decoder layers\n",
        "    dim_feedforward=1024,       # Feedforward dimension\n",
        "    dropout=0.1,                # Dropout rate for regularization\n",
        ")\n",
        "\n",
        "print(\"RegressLM model created successfully!\")\n",
        "print(f\"Model type: {type(reg_lm.model)}\")\n",
        "print(f\"Fine-tuner type: {type(reg_lm.fine_tuner)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Creating Training Examples\n",
        "\n",
        "Let's create some examples that demonstrate different text-to-number relationships:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Sentiment to score mapping\n",
        "sentiment_examples = [\n",
        "    core.Example(x=\"This movie is absolutely fantastic!\", y=0.9),\n",
        "    core.Example(x=\"I loved every minute of it\", y=0.8),\n",
        "    core.Example(x=\"Pretty good movie overall\", y=0.6),\n",
        "    core.Example(x=\"It was okay, nothing special\", y=0.3),\n",
        "    core.Example(x=\"I didn't like it very much\", y=0.1),\n",
        "    core.Example(x=\"Terrible movie, waste of time\", y=0.0),\n",
        "]\n",
        "\n",
        "# Example 2: Simple numerical relationships\n",
        "number_examples = [\n",
        "    core.Example(x=\"The number five\", y=5.0),\n",
        "    core.Example(x=\"ten plus ten\", y=20.0),\n",
        "    core.Example(x=\"three times four\", y=12.0),\n",
        "    core.Example(x=\"half of sixteen\", y=8.0),\n",
        "    core.Example(x=\"seven squared\", y=49.0),\n",
        "]\n",
        "\n",
        "print(f\"Created {len(sentiment_examples)} sentiment examples\")\n",
        "print(f\"Created {len(number_examples)} numerical examples\")\n",
        "\n",
        "# Display some examples\n",
        "print(\"\\nSample sentiment examples:\")\n",
        "for ex in sentiment_examples[:3]:\n",
        "    print(f\"  Text: '{ex.x}' -> Score: {ex.y}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Fine-tuning the Model\n",
        "\n",
        "Let's fine-tune the model on our sentiment examples:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune on sentiment examples\n",
        "print(\"Fine-tuning on sentiment examples...\")\n",
        "reg_lm.fine_tune(\n",
        "    examples=sentiment_examples,\n",
        "    validation_examples=sentiment_examples,  # Using same data for validation (just for demo)\n",
        "    max_epochs=50,  # Reduce epochs for faster training\n",
        "    batch_size=None,  # Use all examples in each batch\n",
        ")\n",
        "print(\"Fine-tuning completed!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Making Predictions\n",
        "\n",
        "Now let's test our fine-tuned model on new text:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inputs\n",
        "test_inputs = [\n",
        "    core.ExampleInput(x=\"This is an amazing film!\"),\n",
        "    core.ExampleInput(x=\"I hate this movie\"),\n",
        "    core.ExampleInput(x=\"The movie was decent\"),\n",
        "    core.ExampleInput(x=\"Best movie ever made\"),\n",
        "    core.ExampleInput(x=\"Boring and pointless\"),\n",
        "]\n",
        "\n",
        "# Generate predictions (multiple samples for uncertainty estimation)\n",
        "num_samples = 10\n",
        "print(f\"Generating {num_samples} samples for each input...\")\n",
        "\n",
        "samples = reg_lm.sample(test_inputs, num_samples=num_samples)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nPrediction Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, test_input in enumerate(test_inputs):\n",
        "    sample_values = samples[i]\n",
        "    mean_pred = np.mean(sample_values)\n",
        "    std_pred = np.std(sample_values)\n",
        "    \n",
        "    print(f\"Text: '{test_input.x}'\")\n",
        "    print(f\"  Mean prediction: {mean_pred:.3f} Â± {std_pred:.3f}\")\n",
        "    print(f\"  Sample range: [{np.min(sample_values):.3f}, {np.max(sample_values):.3f}]\")\n",
        "    print(f\"  All samples: {[f'{x:.3f}' for x in sample_values]}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Visualizing Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a visualization of the predictions\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Mean predictions with error bars\n",
        "test_texts = [inp.x for inp in test_inputs]\n",
        "means = [np.mean(samples[i]) for i in range(len(test_inputs))]\n",
        "stds = [np.std(samples[i]) for i in range(len(test_inputs))]\n",
        "\n",
        "ax1.errorbar(range(len(test_texts)), means, yerr=stds, \n",
        "             marker='o', capsize=5, capthick=2, markersize=8)\n",
        "ax1.set_xticks(range(len(test_texts)))\n",
        "ax1.set_xticklabels([text[:20] + '...' if len(text) > 20 else text \n",
        "                     for text in test_texts], rotation=45, ha='right')\n",
        "ax1.set_ylabel('Predicted Score')\n",
        "ax1.set_title('Sentiment Predictions with Uncertainty')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(-0.1, 1.1)\n",
        "\n",
        "# Plot 2: Distribution of all samples\n",
        "sample_data = [samples[i] for i in range(len(test_inputs))]\n",
        "ax2.boxplot(sample_data, labels=[f'T{i+1}' for i in range(len(test_inputs))])\n",
        "ax2.set_ylabel('Predicted Score')\n",
        "ax2.set_xlabel('Test Input')\n",
        "ax2.set_title('Distribution of Predictions')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "print(f\"Overall mean prediction: {np.mean([np.mean(samples[i]) for i in range(len(test_inputs))]):.3f}\")\n",
        "print(f\"Overall std of means: {np.std([np.mean(samples[i]) for i in range(len(test_inputs))]):.3f}\")\n",
        "print(f\"Average uncertainty (std): {np.mean([np.std(samples[i]) for i in range(len(test_inputs))]):.3f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Next Steps and Ideas for Further Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_ideas = [\n",
        "    \"1. Domain-specific regression: Train on scientific data (e.g., chemical properties from descriptions)\",\n",
        "    \"2. Time series prediction: Use text descriptions of events to predict future values\",\n",
        "    \"3. Multi-output regression: Modify the model to predict multiple values simultaneously\",\n",
        "    \"4. Active learning: Implement uncertainty-based sample selection for training\",\n",
        "    \"5. Evaluation metrics: Implement proper train/validation/test splits and evaluation\",\n",
        "    \"6. Data augmentation: Generate synthetic examples through text paraphrasing\",\n",
        "    \"7. Interpretability: Analyze attention weights to understand model decisions\",\n",
        "    \"8. Transfer learning: Use pre-trained language models as encoders\",\n",
        "    \"9. Robustness testing: Evaluate model performance on adversarial or noisy inputs\",\n",
        "    \"10. Real-world application: Apply to actual business/research problems\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ’¡ Experiment Ideas for Further Exploration:\")\n",
        "print(\"=\" * 50)\n",
        "for idea in experiment_ideas:\n",
        "    print(f\"   {idea}\")\n",
        "\n",
        "print(\"\\nðŸš€ Ready to start experimenting!\")\n",
        "print(\"\\nUseful next steps:\")\n",
        "print(\"- Modify the examples above with your own data\")\n",
        "print(\"- Experiment with different model architectures\")\n",
        "print(\"- Try different fine-tuning strategies\")\n",
        "print(\"- Implement proper evaluation metrics\")\n",
        "print(\"- Scale up to larger datasets\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Quick Reference\n",
        "\n",
        "### Key Classes and Methods:\n",
        "\n",
        "```python\n",
        "# Core data structures\n",
        "from regress_lm import core\n",
        "example = core.Example(x=\"text input\", y=0.5)  # Training example\n",
        "query = core.ExampleInput(x=\"text input\")      # Query without target\n",
        "\n",
        "# Main model class\n",
        "from regress_lm import rlm\n",
        "model = rlm.RegressLM.from_default(\n",
        "    max_input_len=512,\n",
        "    dropout=0.1  # Required parameter!\n",
        ")\n",
        "\n",
        "# Training\n",
        "model.fine_tune(\n",
        "    examples=examples, \n",
        "    validation_examples=None, \n",
        "    max_epochs=100,\n",
        "    batch_size=None,\n",
        "    seed=None\n",
        ")\n",
        "\n",
        "# Inference\n",
        "samples = model.sample([query1, query2], num_samples=10)\n",
        "# Returns: List of numpy arrays, one per query\n",
        "```\n",
        "\n",
        "### Model Parameters:\n",
        "- `max_input_len`: Maximum input sequence length\n",
        "- `learning_rate`: Learning rate for fine-tuning\n",
        "- `d_model`: Model hidden dimension\n",
        "- `nhead`: Number of attention heads\n",
        "- `num_encoder_layers`: Number of encoder transformer layers\n",
        "- `num_decoder_layers`: Number of decoder transformer layers\n",
        "- `dim_feedforward`: Feedforward network dimension\n",
        "- `dropout`: Dropout rate for regularization (required!)\n",
        "\n",
        "### Fine-tuning Parameters:\n",
        "- `examples`: Training examples (required)\n",
        "- `validation_examples`: Validation examples (optional, defaults to training examples)\n",
        "- `max_epochs`: Number of training epochs (default: 100)\n",
        "- `batch_size`: Training batch size (default: None = use all examples)\n",
        "- `seed`: Random seed for reproducibility (default: None)\n",
        "\n",
        "### Getting Started:\n",
        "1. Run all cells in order\n",
        "2. Modify the examples with your own data\n",
        "3. Experiment with different model configurations\n",
        "4. Try different types of text-to-number relationships\n",
        "\n",
        "**Note**: Make sure to include the `dropout` parameter when creating models, as it's required by the architecture!\n",
        "\n",
        "Happy experimenting! ðŸŽ‰\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
